{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "#importando as bibliotecas \n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import sys \n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv \n",
    "import statistics as sts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, '/home/marina/InCi/')\n",
    "from cbirdb import acbirdb,cbirdbDistMatrix,evaluator,unsuperalg,recknngraph\n",
    "\n",
    "execucoes = 10\n",
    "\n",
    "def DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs): \n",
    "\n",
    "    # máscaras \n",
    "\n",
    "    train_mask = [] #máscaras de treino - true = treino \n",
    "    val_mask = [] #valores das máscaras \n",
    "    test_mask = [] #máscaras de testes \n",
    "    y = [] # y = vetor de \"gabarito\" \n",
    "\n",
    "    for i in range (pN):# para cada imagem i: \n",
    "        y.append(i // classSize) # definindo o vetor de classes \n",
    "        d = i % classSize # d = resto do número da imagem dividido pela classe \n",
    "        if (d<trPerClass): # se d é menor que o número de imagens de treino por classe, então: \n",
    "            valueTr = True # treino = true \n",
    "            valueVal = False # teste = false \n",
    "        else: # d é maior ou igual ao número de imagens de treino por classe: \n",
    "            valueTr = False # treino = false \n",
    "            if (d<(valPerClass+trPerClass)): \n",
    "                valueVal = True # teste = true \n",
    "            else:\n",
    "                valueVal = False #teste = false \n",
    "        valueTest = (not valueTr) and (not valueVal) \n",
    "\n",
    "        train_mask.append (valueTr) # criando os vetores de máscaras \n",
    "        val_mask.append(valueVal) #vetor de validação \n",
    "        test_mask.append(valueTest)\n",
    "\n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    train_mask = torch.tensor (train_mask) #torch \n",
    "    val_mask = torch.tensor (val_mask)\n",
    "    test_mask = torch.tensor (test_mask)\n",
    "    y = torch.tensor (y)\n",
    "\n",
    "    \n",
    "    #-------------------------------- Feature Matrix ------------------------------------- \n",
    "    #lendo a matriz de features \n",
    "\n",
    "    #print ('Reading feature matrix ...')\n",
    "    feat_matrix_file = \"matrix_sem_virgulas.txt\" #\"feat-matrix.txt\"\n",
    "    x = np.loadtxt(feat_matrix_file, delimiter=\" \")\n",
    "    #print(x.shape)\n",
    "    x = torch.tensor(x)\n",
    "    #print (x)\n",
    "    \n",
    "    # Indexação das Bordas \n",
    "\n",
    "    #arquivo lista \n",
    "    pListFile = \"list.txt\"\n",
    "    #arquivo dist matrix\n",
    "    pDSimFile = DistM #\"/home/marina/venv/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "\n",
    "\n",
    "    #print ('Reading DB ...')\n",
    "    db1 = cbirdbDistMatrix(pListFile,pDSimFile,pN)\n",
    "    db2 = cbirdbDistMatrix(pListFile,pDSimFile,pN)\n",
    "\n",
    "    #print ('Making edge list ...')\n",
    "    edge_index1 = []\n",
    "    edge_index2 = []\n",
    "\n",
    "    for qimg in db1.getList(): #para cada imagem da lista \n",
    "        # DB ORIGINAL - NO RESTO USAR O DB NOVO \n",
    "        #print (qimg)\n",
    "        crl = db1.getRL(qimg) # mais próximos no ranked list \n",
    "        qindex = db1.getIndexOf(qimg) \n",
    "        for i in range(pK): # cria arestas entre as k posições mais próximas \n",
    "            cindex = db1.getIndexOf (crl[i])\n",
    "            edge_index1.append([qindex,cindex])\n",
    "    \n",
    "    for qimg in db2.getList(): #para cada imagem da lista \n",
    "        # DB ORIGINAL - NO RESTO USAR O DB NOVO \n",
    "        #print (qimg)\n",
    "        crl = db2.getRL(qimg) # mais próximos no ranked list \n",
    "        qindex = db2.getIndexOf(qimg) \n",
    "        for i in range(pK): # cria arestas entre as k posições mais próximas \n",
    "            cindex = db2.getIndexOf (crl[i])\n",
    "            edge_index2.append([qindex,cindex])\n",
    "\n",
    "    #print(edge_index)\n",
    "\n",
    "    #passa para o torch \n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    edge_index = torch.tensor(edge_index)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "\n",
    "    #print (edge_index)\n",
    "    \n",
    "    #--------------------------------- Data Object  -----------------------------------------\n",
    "    #data são as informações do grafo completo (eu acho) *_* \n",
    "\n",
    "    #print ('Loading data object...')\n",
    "    data = Data(x=x.float(), edge_index=edge_index, y=y, test_mask=test_mask, train_mask=train_mask,  val_mask=val_mask  )\n",
    "\n",
    "\n",
    "    #--------------------------------- Graph Neural Network Defiition  -----------------------------------------\n",
    "\n",
    "    # rede neural: NÃO MEXA!!!!!!!!!!\n",
    "\n",
    "    #print ('Defining GCN model...')\n",
    "\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = GCNConv(pNFeatures, pNNeurons) #dataset.num_node_features\n",
    "            self.conv2 = GCNConv(pNNeurons, numberOfClasses) #dataset.num_classes\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cpu')\n",
    "    model = Net().to(device)\n",
    "    #data = dataset[0].to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=pLR, weight_decay=5e-4)\n",
    "\n",
    "    #print ('Training...')\n",
    "\n",
    "    model.train() # treinando com a rede neural \n",
    "    for epoch in range(pNEpochs):\t\n",
    "        #print(\"Training epoch: \", epoch)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # aqui ele avalia o modelo, com base nas máscaras de teste e treino que definimos no começo     \n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / pN #data.test_mask.sum().item() # esse acc é o mesmo da soccer? é um descritor? \n",
    "\n",
    "    #print('Accuracy: {:.4f}'.format(acc)) \n",
    "    return(acc)\n",
    "\n",
    "\n",
    "# informações do dataset\n",
    "pN = 4096 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 300 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8634e70c91e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDasProgrammeHausaufgabe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfClasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrPerClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalPerClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNNeurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdp_udlf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mPoD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-58a673c95dc2>\u001b[0m in \u001b[0;36mDasProgrammeHausaufgabe\u001b[0;34m(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m#print ('Reading DB ...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbirdbDistMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpListFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpDSimFile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#print ('Making edge list ...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/H/cbirdb.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, strListFile, strDistFile, valueN)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalueN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadListFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadSimFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadListFile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/H/cbirdb.py\u001b[0m in \u001b[0;36mreadSimFile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mcurDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mcurDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurDic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcurDic\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/H/cbirdb.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mcurDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mcurDic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurDic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mcurDic\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "DistM = \"matrix_flowers_rlsim_bonita_corrigida.txt\" \n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistM = \"matrix_flowers_rdpac_talvez_bonita_corrigida.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
