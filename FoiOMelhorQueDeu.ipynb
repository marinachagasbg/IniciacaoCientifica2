{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "#importando as bibliotecas \n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import sys \n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv \n",
    "import statistics as sts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, '/home/marina/InCi/')\n",
    "from cbirdb import acbirdb,cbirdbDistMatrix,evaluator,unsuperalg,recknngraph\n",
    "\n",
    "execucoes = 10\n",
    "\n",
    "def DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs): \n",
    "\n",
    "    # máscaras \n",
    "\n",
    "    train_mask = [] #máscaras de treino - true = treino \n",
    "    val_mask = [] #valores das máscaras \n",
    "    test_mask = [] #máscaras de testes \n",
    "    y = [] # y = vetor de \"gabarito\" \n",
    "\n",
    "    for i in range (pN):# para cada imagem i: \n",
    "        y.append(i // classSize) # definindo o vetor de classes \n",
    "        d = i % classSize # d = resto do número da imagem dividido pela classe \n",
    "        if (d<trPerClass): # se d é menor que o número de imagens de treino por classe, então: \n",
    "            valueTr = True # treino = true \n",
    "            valueVal = False # teste = false \n",
    "        else: # d é maior ou igual ao número de imagens de treino por classe: \n",
    "            valueTr = False # treino = false \n",
    "            if (d<(valPerClass+trPerClass)): \n",
    "                valueVal = True # teste = true \n",
    "            else:\n",
    "                valueVal = False #teste = false \n",
    "        valueTest = (not valueTr) and (not valueVal) \n",
    "\n",
    "        train_mask.append (valueTr) # criando os vetores de máscaras \n",
    "        val_mask.append(valueVal) #vetor de validação \n",
    "        test_mask.append(valueTest)\n",
    "\n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    train_mask = torch.tensor (train_mask) #torch \n",
    "    val_mask = torch.tensor (val_mask)\n",
    "    test_mask = torch.tensor (test_mask)\n",
    "    y = torch.tensor (y)\n",
    "\n",
    "    \n",
    "    #-------------------------------- Feature Matrix ------------------------------------- \n",
    "    #lendo a matriz de features \n",
    "\n",
    "    #print ('Reading feature matrix ...')\n",
    "    feat_matrix_file = \"feat-matrix.txt\"\n",
    "    x = np.loadtxt(feat_matrix_file, delimiter=\",\")\n",
    "    #print(x.shape)\n",
    "    x = torch.tensor(x)\n",
    "    #print (x)\n",
    "    \n",
    "    # Indexação das Bordas \n",
    "\n",
    "    #arquivo lista \n",
    "    pListFile = \"list.txt\"\n",
    "    #arquivo dist matrix\n",
    "    pDSimFile = DistM #\"/home/marina/venv/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "\n",
    "\n",
    "    #print ('Reading DB ...')\n",
    "    db = cbirdbDistMatrix(pListFile,pDSimFile,pN)\n",
    "\n",
    "    #print ('Making edge list ...')\n",
    "    edge_index = []\n",
    "\n",
    "    for qimg in db.getList(): #para cada imagem da lista \n",
    "        # DB ORIGINAL - NO RESTO USAR O DB NOVO \n",
    "        #print (qimg)\n",
    "        crl = db.getRL(qimg) # mais próximos no ranked list \n",
    "        qindex = db.getIndexOf(qimg) \n",
    "        for i in range(pK): # cria arestas entre as k posições mais próximas \n",
    "            cindex = db.getIndexOf (crl[i])\n",
    "            edge_index.append([qindex,cindex])\n",
    "\n",
    "    #print(edge_index)\n",
    "\n",
    "    #passa para o torch \n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    edge_index = torch.tensor(edge_index)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "\n",
    "    #print (edge_index)\n",
    "    \n",
    "    #--------------------------------- Data Object  -----------------------------------------\n",
    "    #data são as informações do grafo completo (eu acho) *_* \n",
    "\n",
    "    #print ('Loading data object...')\n",
    "    data = Data(x=x.float(), edge_index=edge_index, y=y, test_mask=test_mask, train_mask=train_mask,  val_mask=val_mask  )\n",
    "\n",
    "\n",
    "    #--------------------------------- Graph Neural Network Defiition  -----------------------------------------\n",
    "\n",
    "    # rede neural: NÃO MEXA!!!!!!!!!!\n",
    "\n",
    "    #print ('Defining GCN model...')\n",
    "\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = GCNConv(pNFeatures, pNNeurons) #dataset.num_node_features\n",
    "            self.conv2 = GCNConv(pNNeurons, numberOfClasses) #dataset.num_classes\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cpu')\n",
    "    model = Net().to(device)\n",
    "    #data = dataset[0].to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=pLR, weight_decay=5e-4)\n",
    "\n",
    "    #print ('Training...')\n",
    "\n",
    "    model.train() # treinando com a rede neural \n",
    "    for epoch in range(pNEpochs):\t\n",
    "        #print(\"Training epoch: \", epoch)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # aqui ele avalia o modelo, com base nas máscaras de teste e treino que definimos no começo     \n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / pN #data.test_mask.sum().item() # esse acc é o mesmo da soccer? é um descritor? \n",
    "\n",
    "    #print('Accuracy: {:.4f}'.format(acc)) \n",
    "    return(acc)\n",
    "\n",
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 300 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos\n",
    "\n",
    "\n",
    "DistM = \"nova_dist_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "DistM = \"CPRR.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Nova Matriz sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistM = \"LHRR.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistM = \"CORGRAPH.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistM = \"BFSTREE.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
