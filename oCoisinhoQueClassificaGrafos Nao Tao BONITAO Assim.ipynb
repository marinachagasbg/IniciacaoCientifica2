{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Nova Matriz sem UDLF:  0.05830882352941176 \n",
      "Desvio Padrão:  0.016165511736532193\n",
      "Nova Matriz com UDLF:  0.32125 \n",
      "Desvio Padrão:  0.15383419838280424\n",
      "Antiga Matriz (café) sem UDLF:  0.17911764705882352\n",
      "Tempo de execução:  20.856146800518037\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "#importando as bibliotecas \n",
    "import torch\n",
    "import torch_geometric\n",
    "import numpy as np\n",
    "import sys \n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F \n",
    "from torch_geometric.nn import GCNConv \n",
    "import statistics as sts\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(1, '/home/marina/InCi/')\n",
    "from cbirdb import acbirdb,cbirdbDistMatrix,evaluator,unsuperalg,recknngraph\n",
    "\n",
    "execucoes = 10\n",
    "\n",
    "def DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs): \n",
    "\n",
    "    # máscaras \n",
    "\n",
    "    train_mask = [] #máscaras de treino - true = treino \n",
    "    val_mask = [] #valores das máscaras \n",
    "    test_mask = [] #máscaras de testes \n",
    "    y = [] # y = vetor de \"gabarito\" \n",
    "\n",
    "    for i in range (pN):# para cada imagem i: \n",
    "        y.append(i // classSize) # definindo o vetor de classes \n",
    "        d = i % classSize # d = resto do número da imagem dividido pela classe \n",
    "        if (d<trPerClass): # se d é menor que o número de imagens de treino por classe, então: \n",
    "            valueTr = True # treino = true \n",
    "            valueVal = False # teste = false \n",
    "        else: # d é maior ou igual ao número de imagens de treino por classe: \n",
    "            valueTr = False # treino = false \n",
    "            if (d<(valPerClass+trPerClass)): \n",
    "                valueVal = True # teste = true \n",
    "            else:\n",
    "                valueVal = False #teste = false \n",
    "        valueTest = (not valueTr) and (not valueVal) \n",
    "\n",
    "        train_mask.append (valueTr) # criando os vetores de máscaras \n",
    "        val_mask.append(valueVal) #vetor de validação \n",
    "        test_mask.append(valueTest)\n",
    "\n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    train_mask = torch.tensor (train_mask) #torch \n",
    "    val_mask = torch.tensor (val_mask)\n",
    "    test_mask = torch.tensor (test_mask)\n",
    "    y = torch.tensor (y)\n",
    "\n",
    "    \n",
    "    #-------------------------------- Feature Matrix ------------------------------------- \n",
    "    #lendo a matriz de features \n",
    "\n",
    "    #print ('Reading feature matrix ...')\n",
    "    feat_matrix_file = \"feat-matrix.txt\"\n",
    "    x = np.loadtxt(feat_matrix_file, delimiter=\",\")\n",
    "    #print(x.shape)\n",
    "    x = torch.tensor(x)\n",
    "    #print (x)\n",
    "    \n",
    "    # Indexação das Bordas \n",
    "\n",
    "    #arquivo lista \n",
    "    pListFile = \"list.txt\"\n",
    "    #arquivo dist matrix\n",
    "    pDSimFile = DistM #\"/home/marina/venv/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "\n",
    "\n",
    "    #print ('Reading DB ...')\n",
    "    db = cbirdbDistMatrix(pListFile,pDSimFile,pN)\n",
    "\n",
    "    #print ('Making edge list ...')\n",
    "    edge_index = []\n",
    "\n",
    "    for qimg in db.getList(): #para cada imagem da lista \n",
    "        #print (qimg)\n",
    "        crl = db.getRL(qimg) # mais próximos no ranked list \n",
    "        qindex = db.getIndexOf(qimg) \n",
    "        for i in range(pK): # cria arestas entre as k posições mais próximas \n",
    "            cindex = db.getIndexOf (crl[i])\n",
    "            edge_index.append([qindex,cindex])\n",
    "\n",
    "    #print(edge_index)\n",
    "\n",
    "    #passa para o torch \n",
    "    # A torch.Tensor is a multi-dimensional matrix containing elements of a single data type.\n",
    "    edge_index = torch.tensor(edge_index)\n",
    "    edge_index = edge_index.t().contiguous()\n",
    "\n",
    "    #print (edge_index)\n",
    "    \n",
    "    #--------------------------------- Data Object  -----------------------------------------\n",
    "    #data são as informações do grafo completo (eu acho) *_* \n",
    "\n",
    "    #print ('Loading data object...')\n",
    "    data = Data(x=x.float(), edge_index=edge_index, y=y, test_mask=test_mask, train_mask=train_mask,  val_mask=val_mask  )\n",
    "\n",
    "\n",
    "    #--------------------------------- Graph Neural Network Defiition  -----------------------------------------\n",
    "\n",
    "    # rede neural: NÃO MEXA!!!!!!!!!!\n",
    "\n",
    "    #print ('Defining GCN model...')\n",
    "\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = GCNConv(pNFeatures, pNNeurons) #dataset.num_node_features\n",
    "            self.conv2 = GCNConv(pNNeurons, numberOfClasses) #dataset.num_classes\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, edge_index = data.x, data.edge_index\n",
    "\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.conv2(x, edge_index)\n",
    "\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #device = torch.device('cpu')\n",
    "    model = Net().to(device)\n",
    "    #data = dataset[0].to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=pLR, weight_decay=5e-4)\n",
    "\n",
    "    #print ('Training...')\n",
    "\n",
    "    model.train() # treinando com a rede neural \n",
    "    for epoch in range(pNEpochs):\t\n",
    "        #print(\"Training epoch: \", epoch)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # aqui ele avalia o modelo, com base nas máscaras de teste e treino que definimos no começo     \n",
    "    model.eval()\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "    acc = correct / pN #data.test_mask.sum().item() # esse acc é o mesmo da soccer? é um descritor? \n",
    "\n",
    "    #print('Accuracy: {:.4f}'.format(acc)) \n",
    "    return(acc)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 32 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "DistM = \"oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "\n",
    "'''\n",
    "vpk = []\n",
    "vpn = []\n",
    "\n",
    "dpk = []\n",
    "dpn = []\n",
    "\n",
    "for i in range(execucoes): \n",
    "    vpk.append(0)\n",
    "    vpn.append(0)\n",
    "\n",
    "print(vpk)\n",
    "print(vpn)\n",
    "\n",
    "for i in range(execucoes):\n",
    "    print(\"Execução num \", i)\n",
    "    pK = 25\n",
    "    pNNeurons = 24\n",
    "    VariaKs = []\n",
    "    VariaNeuronios = []\n",
    "\n",
    "    while pK <= 50: \n",
    "        print(\"K: \", pK)\n",
    "        m = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "        VariaKs.append(m)\n",
    "        pK = pK + 5        \n",
    "\n",
    "    while pNNeurons <= 36: \n",
    "        print(\"Neurônio: \", pNNeurons)\n",
    "        c = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "        VariaNeuronios.append(c)\n",
    "        pNNeurons = pNNeurons + 4\n",
    "        \n",
    "    dpk.append(VariaKs)\n",
    "    dpn.append(VariaNeuronios)\n",
    "\n",
    "    print(\"O PROBLEMA: \")\n",
    "    print(len(VariaKs))\n",
    "    print(len(VariaNeuronios))\n",
    "    print(vpk)\n",
    "    print(vpn)\n",
    "    \n",
    "    for k in range(len(VariaKs)):\n",
    "        vpk[k] = vpk[k] + VariaKs[k]\n",
    "        \n",
    "    for k in range(len(VariaNeuronios)):\n",
    "        vpn[k] = vpn[k] + VariaNeuronios[k]\n",
    "        \n",
    "print(\"\\nFim do Loop\")\n",
    "\n",
    "for k in range(len(vpk)):\n",
    "    vpk[k] = vpk[k]/execucoes\n",
    "    \n",
    "for k in range(len(vpn)):\n",
    "    vpn[k] = vpn[k]/execucoes\n",
    "\n",
    "print(\"\\ndpk: \", dpk)\n",
    "print(\"\\ndpn: \", dpn)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "t = np.asarray([[1, 2, 3], ['a', 'b', 'c']])\n",
    "print(t.shape)\n",
    "print(t[:, 0])\n",
    "'''\n",
    "'''\n",
    "media_k = []\n",
    "media_N = []\n",
    "j = 0 \n",
    "stdevK = []\n",
    "stdevN = []\n",
    "\n",
    "dpk = np.asarray(dpk)\n",
    "print(dpk.shape)\n",
    "for i in range( dpk.shape[1] ):# para cada linha (10)\n",
    "    for coluna in dpk[:, i]: #para elemento da coluna\n",
    "        j = j + coluna # j é a soma de todos os elementos da coluna \n",
    "    # saiu do for \n",
    "    stdevK.append(sts.stdev(dpk[:, i])) # desvio padrão da coluna \n",
    "    j = j/dpk.shape[1] # j é a média da coluna \n",
    "    media_k.append(j)\n",
    "    j = 0\n",
    "    \n",
    "j = 0\n",
    "dpn = np.asarray(dpn)\n",
    "print(dpn.shape)\n",
    "for i in range( dpn.shape[1] ):# para cada linha (10)\n",
    "    for coluna in dpn[:, i]: #para elemento da coluna\n",
    "        j = j + coluna # j é a soma de todos os elementos da coluna \n",
    "    # saiu do for \n",
    "    stdevN.append(sts.stdev(dpn[:, i])) # desvio padrão da coluna \n",
    "    j = j/dpn.shape[1] # j é a média da coluna \n",
    "    media_N.append(j)\n",
    "teste = [1, 2, 3, 4, 5, 6]\n",
    "media_k = np.asarray(media_k)\n",
    "media_N = np.asarray(media_N)\n",
    "print(media_k)\n",
    "print(media_N)\n",
    "stdevK = np.asarray(stdevK)\n",
    "stdevN = np.asarray(stdevN)\n",
    "print(stdevK)\n",
    "print(stdevN)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.show( plt.errorbar(x = [25, 30, 35, 40, 45, 50], y = media_k, yerr = stdevK, fmt = '-o') )\n",
    "plt.show(plt.errorbar(x = [24, 28, 32, 36], y = media_N, yerr = stdevN, fmt = '-o'))\n",
    "\n",
    "'''\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "'''gerar uma nova matriz de distância, com base nas features '''\n",
    "'''variar o k de 25 a 50, de 5 em 5 \n",
    "variar neurônios de 24 a 36, de 4 em 4 \n",
    "'''\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 40 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 36 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"nova_dist_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "\n",
    "for i in range(10): \n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "DistM = \"Nova_Matrix_UDLF.txt\"\n",
    "PoD = 0 \n",
    "dp_udlf = []\n",
    "for i in range(11): \n",
    "    print(i)\n",
    "    AP = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(AP)\n",
    "    PoD = PoD + AP\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "DistM = \"oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "PoDo = 0 \n",
    "dp_udlf = []\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    APO = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_udlf.append(APO)\n",
    "    PoDo = PoDo + APO\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Nova Matriz sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))\n",
    "PoD = PoD/execucoes\n",
    "print(\"Nova Matriz com UDLF: \", PoD, \"\\nDesvio Padrão: \", sts.stdev(dp_udlf))\n",
    "print(\"Antiga Matriz (café) sem UDLF: \", PoDo/execucoes)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "t2 = time.time()\n",
    "print(\"Tempo de execução: \", (t2-t1)/60 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.14985294117647058 \n",
      "Desvio Padrão:  0.16067173844694418\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 80 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 36 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.17786764705882352 \n",
      "Desvio Padrão:  0.09336495000206924\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 8 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 36 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.3386029411764706 \n",
      "Desvio Padrão:  0.15561940224920986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 50 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.36389705882352935 \n",
      "Desvio Padrão:  0.1576567107875936\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 15 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 60 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.3770588235294117 \n",
      "Desvio Padrão:  0.11035934890185921\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 55 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.3741911764705882 \n",
      "Desvio Padrão:  0.13656842070983605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 55 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Café sem UDLF:  0.5516911764705882 \n",
      "Desvio Padrão:  0.006950161045766613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 505 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-88b650d2dc32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mNM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDasProgrammeHausaufgabe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDistM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfClasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrPerClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalPerClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNNeurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mdp_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mMedia_NM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMedia_NM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8985e62b294d>\u001b[0m in \u001b[0;36mDasProgrammeHausaufgabe\u001b[0;34m(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 5000 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.01 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.0001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.005 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 200 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 100 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# informações do dataset\n",
    "pN = 1360 \n",
    "classSize = 80\n",
    "numberOfClasses = 17\n",
    "\n",
    "pNFeatures = 4096 # número de features \n",
    "\n",
    "# parâmetros \n",
    "trPerClass = 20 #treinamento por classe \n",
    "valPerClass = 0*trPerClass #valores por classe \n",
    "\n",
    "pK = 35 # número de vizinhos mais próximos (serve para gerar o grafo)\n",
    "pLR = 0.001 # learning rate: o quão rápido os pesos são atualizados (não mexer)\n",
    "pNNeurons = 500 # quantidade de neurônios nas camadas intermediárias (serve para otimizar)\n",
    "pNEpochs = 300 # quantidade de interações de treinamento a cada época (calcula e ajusta os pesos)\n",
    "# época = rodada de ajustes de pesos \n",
    "\n",
    "\n",
    "DistM = \"/home/marina/Documents/H/oxford17flowers-caffe-fc7_matrix.txt\"\n",
    "Media_NM = 0\n",
    "dp_original = []\n",
    "\n",
    "for i in range(10): \n",
    "    print(i)\n",
    "    NM = DasProgrammeHausaufgabe(DistM, pN, classSize, numberOfClasses, pNFeatures, trPerClass, valPerClass, pK, pLR, pNNeurons, pNEpochs)\n",
    "    dp_original.append(NM)\n",
    "    Media_NM = Media_NM + NM\n",
    "\n",
    "Media_NM = Media_NM/execucoes \n",
    "print(\"Café sem UDLF: \", Media_NM, \"\\nDesvio Padrão: \", sts.stdev(dp_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
